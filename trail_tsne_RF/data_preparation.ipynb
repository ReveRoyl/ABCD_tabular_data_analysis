{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Makka Papa\\AppData\\Local\\Temp\\ipykernel_10964\\38619458.py:51: DtypeWarning: Columns (124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  file2 = pd.read_csv(file2_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import nni\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Base directory path\n",
    "base_path = \"G:\\ABCD\\data\"\n",
    "\n",
    "# File paths using the base path\n",
    "file1_1_path = f\"{base_path}/mri_y_rsfmr_cor_gp_aseg.csv\"\n",
    "file1_2_path = f\"{base_path}/mri_y_rsfmr_cor_gp_gp.csv\"\n",
    "file1_3_path = f\"{base_path}/mri_y_rsfmr_var_aseg.csv\"\n",
    "file1_4_path = f\"{base_path}/mri_y_rsfmr_var_dsk.csv\"\n",
    "file1_5_path = f\"{base_path}/mri_y_rsfmr_var_dst.csv\"\n",
    "file1_6_path = f\"{base_path}/mri_y_rsfmr_var_gp.csv\"\n",
    "\n",
    "\n",
    "file2_path = f\"{base_path}/mh_p_cbcl.csv\"\n",
    "\n",
    "\n",
    "file1_1 = pd.read_csv(file1_1_path)\n",
    "file1_2 = pd.read_csv(file1_2_path)\n",
    "file1_3 = pd.read_csv(file1_3_path)\n",
    "file1_4 = pd.read_csv(file1_4_path)\n",
    "file1_5 = pd.read_csv(file1_5_path)\n",
    "file1_6 = pd.read_csv(file1_6_path)\n",
    "\n",
    "dfs = [file1_1, file1_2, file1_3, file1_4, file1_5, file1_6]\n",
    "\n",
    "dfs = [df[df['eventname'] == 'baseline_year_1_arm_1'].drop(columns=['eventname']) for df in dfs]\n",
    "\n",
    "# 分别将筛选后的数据框赋值回原来的变量\n",
    "file1_1, file1_2, file1_3, file1_4, file1_5, file1_6 = dfs\n",
    "\n",
    "\n",
    "file1 = pd.merge(file1_1, file1_2, on='src_subject_id', how='inner')\n",
    "file1 = pd.merge(file1, file1_3, on='src_subject_id', how='inner')\n",
    "file1 = pd.merge(file1, file1_4, on='src_subject_id', how='inner')\n",
    "file1 = pd.merge(file1, file1_5, on='src_subject_id', how='inner')\n",
    "file1 = pd.merge(file1, file1_6, on='src_subject_id', how='inner')\n",
    "\n",
    "file1 = file1.loc[:, file1.isnull().mean() < .5]\n",
    "\n",
    "\n",
    "file2 = pd.read_csv(file2_path)\n",
    "\n",
    "file2_baseline_filtered = file2[file2['eventname'] == 'baseline_year_1_arm_1']\n",
    "\n",
    "#drop score\n",
    "file2_drop = file2_baseline_filtered.loc[:, ~file2_baseline_filtered.columns.str.endswith(('_r', '_t', '_m', '_nm', '_nm_2', '___1'))]\n",
    "#drop eventname\n",
    "file2_drop = file2_drop.drop(columns=['eventname'])\n",
    "file2_final_cleaned = file2_drop.dropna(axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(file1, file2_final_cleaned, on='src_subject_id', how='inner')\n",
    "merged_data = merged_data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file1.to_csv('features.csv')\n",
    "# file2_final_cleaned.to_csv('labels.csv')\n",
    "merged_data.to_csv('merged.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
