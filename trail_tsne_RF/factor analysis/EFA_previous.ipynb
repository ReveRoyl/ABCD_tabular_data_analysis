{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity, calculate_kmo\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"G:\\ABCD\\script/trail/trail_tsne_RF\"\n",
    "# load data and drop the first column and the subject id\n",
    "data = pd.read_csv(data_path + \"/merged.csv\").drop(columns=[\"Unnamed: 0\", \"src_subject_id\"])\n",
    "label_columns = data.columns[data.columns.str.startswith(\"cbcl\")].tolist()\n",
    "\n",
    "data = data[label_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EFA from previous research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed columns with low frequency: ['cbcl_q02_p', 'cbcl_q73_p', 'cbcl_q99_p', 'cbcl_q101_p', 'cbcl_q105_p']\n",
      "Highly correlated pairs (r > 0.75): [('cbcl_q08_p', 'cbcl_q10_p'), ('cbcl_q08_p', 'cbcl_q78_p'), ('cbcl_q20_p', 'cbcl_q21_p'), ('cbcl_q21_p', 'cbcl_q106_p'), ('cbcl_q22_p', 'cbcl_q28_p'), ('cbcl_q23_p', 'cbcl_q28_p'), ('cbcl_q25_p', 'cbcl_q48_p'), ('cbcl_q53_p', 'cbcl_q55_p'), ('cbcl_q56c_p', 'cbcl_q56f_p'), ('cbcl_q57_p', 'cbcl_q97_p'), ('cbcl_q81_p', 'cbcl_q82_p')]\n"
     ]
    }
   ],
   "source": [
    "# delete columns with low frequency (more than 99.5% of the values are 0)\n",
    "low_frequency_columns = data.columns[data.apply(lambda col: (col == 0).mean() > 0.995)]\n",
    "data_cleaned = data.drop(columns=low_frequency_columns)\n",
    "print(f\"Removed columns with low frequency: {low_frequency_columns.tolist()}\")\n",
    "\n",
    "#load corerlation matrix from polychoric correlation matrix\n",
    "\n",
    "correlation_matrix = pd.read_csv(data_path + \"/factor analysis/polychoric_correlation_matrix.csv\", index_col=0)\n",
    "\n",
    "# mark highly correlated pairs (r > 0.75)\n",
    "high_corr_pairs = (correlation_matrix.abs() > 0.75).where(lambda x: np.triu(x, 1)).stack().index.tolist()\n",
    "print(f\"Highly correlated pairs (r > 0.75): {high_corr_pairs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of connected groups: 8\n",
      "columns for each connected group: [('cbcl_q08_p', 'cbcl_q10_p', 'cbcl_q78_p'), ('cbcl_q106_p', 'cbcl_q20_p', 'cbcl_q21_p'), ('cbcl_q22_p', 'cbcl_q23_p', 'cbcl_q28_p'), ('cbcl_q25_p', 'cbcl_q48_p'), ('cbcl_q53_p', 'cbcl_q55_p'), ('cbcl_q56c_p', 'cbcl_q56f_p'), ('cbcl_q57_p', 'cbcl_q97_p'), ('cbcl_q81_p', 'cbcl_q82_p')]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def find_connected_groups(pairs):\n",
    "    # 建立图结构\n",
    "    graph = defaultdict(set)\n",
    "    for col1, col2 in pairs:\n",
    "        graph[col1].add(col2)\n",
    "        graph[col2].add(col1)\n",
    "    \n",
    "    # 深度优先搜索（DFS）找到所有连通分量\n",
    "    visited = set()\n",
    "    connected_groups = []\n",
    "\n",
    "    def dfs(node, group):\n",
    "        visited.add(node)\n",
    "        group.add(node)\n",
    "        for neighbor in graph[node]:\n",
    "            if neighbor not in visited:\n",
    "                dfs(neighbor, group)\n",
    "\n",
    "    # 遍历所有节点，找到每个连通分量\n",
    "    for node in graph:\n",
    "        if node not in visited:\n",
    "            group = set()\n",
    "            dfs(node, group)\n",
    "            connected_groups.append(tuple(sorted(group)))\n",
    "\n",
    "    return connected_groups\n",
    "\n",
    "# 使用函数\n",
    "result = find_connected_groups(high_corr_pairs)\n",
    "print(\"number of connected groups:\", len(result))\n",
    "print(\"columns for each connected group:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe to store the final data\n",
    "data_final = data_cleaned.copy()\n",
    "for group in result:\n",
    "    # calculate the average of the columns in the group\n",
    "    data_final[f\"avg_{'_'.join(group)}\"] = data_cleaned[list(group)].mean(axis=1).round().astype(int)\n",
    "    # delete the original columns\n",
    "    data_final.drop(columns=list(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #scale data_final\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# data_scaled = scaler.fit_transform(data_final)\n",
    "\n",
    "# #make data_scaled to dataframe\n",
    "# data_scaled = pd.DataFrame(data_scaled, columns=data_final.columns)\n",
    "data_scaled = data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bartlett's Test Chi-square: 515315.3694519205, p-value: 0.0\n",
      "KMO Test Score: 0.94879737086253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\PhD\\Lib\\site-packages\\factor_analyzer\\utils.py:244: UserWarning: The inverse of the variance-covariance matrix was calculated using the Moore-Penrose generalized matrix inversion, due to its determinant being at or very close to zero.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factor Loadings DataFrame:\n",
      "                              Factor 1  Factor 2  Factor 3  Factor 4  Factor 5  \\\n",
      "cbcl_q01_p                   0.211555 -0.012814  0.391568 -0.036343  0.016208   \n",
      "cbcl_q03_p                   0.761260 -0.010440  0.040119 -0.004430  0.000960   \n",
      "cbcl_q04_p                   0.138168 -0.084475  0.713752  0.025443  0.033466   \n",
      "cbcl_q05_p                   0.301061 -0.144140  0.099289 -0.026919  0.004506   \n",
      "cbcl_q06_p                  -0.024992 -0.047099  0.010108 -0.055517  0.012824   \n",
      "...                               ...       ...       ...       ...       ...   \n",
      "avg_cbcl_q25_p_cbcl_q48_p   -0.090328 -0.020791 -0.179116  0.013832 -0.013794   \n",
      "avg_cbcl_q53_p_cbcl_q55_p   -0.008985  0.028284 -0.027917 -0.062178  0.978707   \n",
      "avg_cbcl_q56c_p_cbcl_q56f_p  0.005110  0.013183 -0.037452  0.974309 -0.025605   \n",
      "avg_cbcl_q57_p_cbcl_q97_p   -0.069001  0.043082  0.037655  0.056761  0.013820   \n",
      "avg_cbcl_q81_p_cbcl_q82_p   -0.115884  0.028409  0.005127  0.000674  0.017981   \n",
      "\n",
      "                             Factor 6  Factor 7  Factor 8  Factor 9  \\\n",
      "cbcl_q01_p                   0.087565  0.172659 -0.020611 -0.017585   \n",
      "cbcl_q03_p                  -0.028762 -0.027329 -0.040783 -0.072585   \n",
      "cbcl_q04_p                  -0.009968 -0.093777  0.050694  0.011469   \n",
      "cbcl_q05_p                  -0.073890  0.053527  0.360217 -0.049043   \n",
      "cbcl_q06_p                   0.006474  0.034821  0.067939  0.010139   \n",
      "...                               ...       ...       ...       ...   \n",
      "avg_cbcl_q25_p_cbcl_q48_p   -0.100251  1.094391 -0.019335 -0.012775   \n",
      "avg_cbcl_q53_p_cbcl_q55_p    0.026893  0.029291 -0.028568  0.022681   \n",
      "avg_cbcl_q56c_p_cbcl_q56f_p  0.105017  0.053533 -0.121029  0.013157   \n",
      "avg_cbcl_q57_p_cbcl_q97_p    0.221573 -0.080783  0.041491 -0.015819   \n",
      "avg_cbcl_q81_p_cbcl_q82_p    0.086155 -0.013213 -0.088803  1.084334   \n",
      "\n",
      "                             Factor 10  Factor 11  Factor 12  Factor 13  \\\n",
      "cbcl_q01_p                   -0.021684  -0.109475   0.041595  -0.148125   \n",
      "cbcl_q03_p                   -0.021733  -0.019169   0.275957  -0.063445   \n",
      "cbcl_q04_p                    0.044301  -0.030689   0.168358  -0.122191   \n",
      "cbcl_q05_p                    0.043751   0.044280   0.039466   0.030431   \n",
      "cbcl_q06_p                    0.020390   0.003262  -0.046495   0.012976   \n",
      "...                                ...        ...        ...        ...   \n",
      "avg_cbcl_q25_p_cbcl_q48_p     0.021931   0.044512   0.126497   0.014571   \n",
      "avg_cbcl_q53_p_cbcl_q55_p     0.012908   0.019153  -0.001203  -0.060923   \n",
      "avg_cbcl_q56c_p_cbcl_q56f_p   0.008834   0.060814   0.005133  -0.136878   \n",
      "avg_cbcl_q57_p_cbcl_q97_p    -0.004758   0.994578  -0.196526  -0.233355   \n",
      "avg_cbcl_q81_p_cbcl_q82_p    -0.002630  -0.039105   0.077438  -0.149649   \n",
      "\n",
      "                             Factor 14  Factor 15  Factor 16  \n",
      "cbcl_q01_p                   -0.123794   0.098232   0.017203  \n",
      "cbcl_q03_p                    0.129309  -0.001004   0.022778  \n",
      "cbcl_q04_p                    0.072833  -0.072326   0.017340  \n",
      "cbcl_q05_p                   -0.104862   0.002722  -0.003685  \n",
      "cbcl_q06_p                   -0.011685   0.011290   0.545101  \n",
      "...                                ...        ...        ...  \n",
      "avg_cbcl_q25_p_cbcl_q48_p     0.020035  -0.059340   0.036633  \n",
      "avg_cbcl_q53_p_cbcl_q55_p    -0.012549  -0.026251   0.053715  \n",
      "avg_cbcl_q56c_p_cbcl_q56f_p  -0.102460   0.000951  -0.081292  \n",
      "avg_cbcl_q57_p_cbcl_q97_p     0.065681   0.075135  -0.072822  \n",
      "avg_cbcl_q81_p_cbcl_q82_p    -0.115214  -0.041128  -0.051739  \n",
      "\n",
      "[122 rows x 16 columns]\n",
      "Variance Explained:\n",
      " (array([7.17591178, 3.04192163, 7.71087628, 3.80624887, 2.80206147,\n",
      "       3.25707226, 4.39340333, 3.62526233, 3.50951263, 2.70980761,\n",
      "       4.09205053, 3.19571493, 2.96283048, 2.76191951, 2.37828656,\n",
      "       1.58243574]), array([0.05881895, 0.02493378, 0.0632039 , 0.03119876, 0.02296772,\n",
      "       0.02669731, 0.0360115 , 0.02971527, 0.0287665 , 0.02221154,\n",
      "       0.0335414 , 0.02619438, 0.0242855 , 0.02263868, 0.01949415,\n",
      "       0.01297078]), array([0.05881895, 0.08375273, 0.14695664, 0.1781554 , 0.20112312,\n",
      "       0.22782043, 0.26383193, 0.2935472 , 0.32231369, 0.34452523,\n",
      "       0.37806663, 0.40426101, 0.42854651, 0.45118519, 0.47067935,\n",
      "       0.48365013]))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity, calculate_kmo\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Bartlett 和 KMO 测试\n",
    "chi_square_value, p_value = calculate_bartlett_sphericity(data_scaled)\n",
    "print(f\"Bartlett's Test Chi-square: {chi_square_value}, p-value: {p_value}\")\n",
    "kmo_all, kmo_model = calculate_kmo(data_scaled)\n",
    "print(f\"KMO Test Score: {kmo_model}\")\n",
    "\n",
    "# factor analysis\n",
    "fa = FactorAnalyzer(n_factors=16,  rotation=\"promax\", method = 'principal')\n",
    "# fa = FactorAnalyzer(n_factors=5, rotation=\"varimax\")\n",
    "# fa.fit(data_cleaned)\n",
    "fa.fit(data_scaled)\n",
    "\n",
    "# factor loadings\n",
    "factor_loadings = fa.loadings_\n",
    "# factor_loadings_df = pd.DataFrame(factor_loadings, columns=[\"Factor 1\", \"Factor 2\", \"Factor 3\", \"Factor 4\", \"Factor 5\", \"Factor 6\"])\n",
    "factor_loadings_df = pd.DataFrame(factor_loadings, columns=[f\"Factor {i}\" for i in range(1, 17)])\n",
    "# factor_loadings_df = pd.DataFrame(factor_loadings, columns=[\"Factor 1\", \"Factor 2\", \"Factor 3\", \"Factor 4\", \"Factor 5\"])\n",
    "# factor_loadings_df.index = data_cleaned.columns\n",
    "factor_loadings_df.index = data_final.columns\n",
    "print(\"Factor Loadings DataFrame:\\n\", factor_loadings_df)\n",
    "\n",
    "# variance explained\n",
    "variance_explained = fa.get_factor_variance()\n",
    "print(\"Variance Explained:\\n\", variance_explained)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05881895, 0.02493378, 0.0632039 , 0.03119876, 0.02296772,\n",
       "       0.02669731, 0.0360115 , 0.02971527, 0.0287665 , 0.02221154,\n",
       "       0.0335414 , 0.02619438, 0.0242855 , 0.02263868, 0.01949415,\n",
       "       0.01297078])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance_explained[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
