{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': {'_type': 'randint', '_value': [50, 200]}, 'max_depth': {'_type': 'randint', '_value': [10, 30]}, 'min_samples_split': {'_type': 'choice', '_value': [10, 20]}, 'min_samples_leaf': {'_type': 'choice', '_value': [30, 40]}, 'n_components': {'_type': 'choice', '_value': [2, 3]}, 'perplexity': {'_type': 'uniform', '_value': [5, 50]}, 'learning_rate': {'_type': 'choice', '_value': ['auto', 10, 1000]}, 'metric': {'_type': 'choice', '_value': ['euclidean', 'l1', 'l2', 'cosine']}}\n",
      "Next params: {'n_estimators': 131, 'max_depth': 23, 'min_samples_split': 10, 'min_samples_leaf': 40, 'n_components': 3, 'perplexity': 18.570487610862727, 'learning_rate': 1000, 'metric': 'euclidean'}\n"
     ]
    }
   ],
   "source": [
    "#simulate nni tuner to generate next parameter\n",
    "import json\n",
    "import random\n",
    "\n",
    "# 读取 search_space.json 文件\n",
    "with open('search_space.json', 'r') as f:\n",
    "    search_space = json.load(f)\n",
    "\n",
    "print(search_space)\n",
    "\n",
    "\n",
    "def get_next_parameter(search_space):\n",
    "    params = {}\n",
    "    for key, value in search_space.items():\n",
    "        param_type = value[\"_type\"]\n",
    "        param_values = value[\"_value\"]\n",
    "\n",
    "        # 根据 _type 生成对应的值\n",
    "        if param_type == \"randint\":\n",
    "            params[key] = random.randint(param_values[0], param_values[1])\n",
    "        elif param_type == \"uniform\":\n",
    "            params[key] = random.uniform(param_values[0], param_values[1])\n",
    "        elif param_type == \"choice\":\n",
    "            params[key] = random.choice(param_values)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown parameter type: {param_type}\")\n",
    "    \n",
    "    return params\n",
    "\n",
    "# 调用函数获取下一个参数\n",
    "params = get_next_parameter(search_space)\n",
    "print(\"Next params:\", params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import nni\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "data_path = \"G:\\ABCD\\script/trail/trail_tsne_RF\"\n",
    "# load data and drop the first column and the subject id\n",
    "data = pd.read_csv(data_path + \"/merged.csv\").drop(columns=[\"Unnamed: 0\", \"src_subject_id\"])\n",
    "\n",
    "# params = nni.get_next_parameter()\n",
    "params = get_next_parameter(search_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns to drop: 'src_subject_id' and all columns not starting with 'cbcl'\n",
    "label_columns = data.columns[data.columns.str.startswith(\"cbcl\")].tolist()\n",
    "\n",
    "# Drop those columns from merged_data to create X\n",
    "X = data.drop(columns = label_columns)\n",
    "\n",
    "y = data[label_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(\n",
    "        n_components=params['n_components'],\n",
    "        perplexity=params['perplexity'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        metric=params['metric'],\n",
    "        random_state=42\n",
    "    )\n",
    "y_tsne = tsne.fit_transform(y).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestRegressor(\n",
    "        n_estimators=params['n_estimators'],\n",
    "        max_depth=params['max_depth'],\n",
    "        min_samples_split=params['min_samples_split'],\n",
    "        min_samples_leaf=params['min_samples_leaf'],\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X, y_tsne, cv=5, scoring='r2')\n",
    "\n",
    "# Report the mean R2 score from cross-validation to NNI\n",
    "mean_cv_r2 = cv_scores.mean()\n",
    "nni.report_final_result(mean_cv_r2)\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(f'10-Fold Cross-Validation R2 Scores: {cv_scores}')\n",
    "print(f'Mean R2 Score from 10-Fold Cross-Validation: {mean_cv_r2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
