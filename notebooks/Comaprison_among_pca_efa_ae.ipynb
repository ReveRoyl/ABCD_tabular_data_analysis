{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e16a6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Global env + basic seeds set, seed = 52\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Comparison among PCA, EFA, and Autoencoder on MSE and EVR\n",
    "import os\n",
    "\n",
    "seed = 52\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "print(\">>> Global env + basic seeds set, seed =\", seed)\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from model_code import AE, set_deterministic, _total_evr_from_recon\n",
    "from validators import build_10_items_validators, build_validators_baseline, build_model_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dir = Path.cwd()\n",
    "data_path = code_dir.parent / 'data'\n",
    "data_file = data_path / 'cbcl_data_remove_low_frequency.csv'\n",
    "if not data_file.exists():\n",
    "    raise FileNotFoundError(f'Could not find {data_file}')\n",
    "\n",
    "qns = pd.read_csv(data_file, encoding='utf-8')\n",
    "X = qns.iloc[:, 1:].values\n",
    "\n",
    "\n",
    "X_train_raw, X_temp = train_test_split(X, test_size=0.2, random_state=seed)\n",
    "X_val_raw, X_test_raw = train_test_split(X_temp, test_size=0.5, random_state=seed)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train_raw)\n",
    "X_val = scaler.transform(X_val_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "n_factors = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EFA -> MSE=0.737914, Total EVR=0.2621\n",
      "PCA -> MSE=0.728905, Total EVR=0.2711\n"
     ]
    }
   ],
   "source": [
    "fa = FactorAnalyzer(n_factors=n_factors, rotation='geomin_obl')\n",
    "fa.fit(X_scaled)\n",
    "efa_scores = fa.transform(X_scaled)\n",
    "X_recon_efa = efa_scores @ fa.loadings_.T\n",
    "mse_efa = float(np.mean((X_scaled - X_recon_efa) ** 2))\n",
    "evr_efa = _total_evr_from_recon(X_scaled, X_recon_efa)\n",
    "\n",
    "pca = PCA(n_components=n_factors)\n",
    "pca_scores = pca.fit_transform(X_scaled)\n",
    "X_recon_pca = pca.inverse_transform(pca_scores)\n",
    "mse_pca = float(np.mean((X_scaled - X_recon_pca) ** 2))\n",
    "evr_pca = _total_evr_from_recon(X_scaled, X_recon_pca)\n",
    "\n",
    "print(f'EFA -> MSE={mse_efa:.6f}, Total EVR={evr_efa:.4f}')\n",
    "print(f'PCA -> MSE={mse_pca:.6f}, Total EVR={evr_pca:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Seed fixed] random/numpy/torch all set to 52\n",
      "Using device: cuda\n",
      "Early stopping at epoch 100\n",
      "Evaluating on test set: EVR test = 0.3718\n",
      "AE -> MSE=0.579299, Total EVR=0.4208\n"
     ]
    }
   ],
   "source": [
    "set_deterministic(seed)\n",
    "\n",
    "autoencoder = AE(\n",
    "    X_train,\n",
    "    X_val,\n",
    "    encoding_dim=5,\n",
    "    h1=192,\n",
    "    h2=64,\n",
    "    seed=seed,\n",
    "    lr=0.003,\n",
    "    lambda_decorr=0.005,\n",
    "    weight_decay=8e-05,\n",
    ")\n",
    "autoencoder.train(show_plot=False)\n",
    "\n",
    "latent_factors, _, _, evr_test, reconstructed, _ = autoencoder.evaluate_on_data(X_test)\n",
    "print(f\"Evaluating on test set: EVR test = {evr_test:.4f}\")\n",
    "\n",
    "latent_factors, _, _, evr_total, reconstructed, _ = autoencoder.evaluate_on_data(X_scaled)\n",
    "mse_ae = float(np.mean((X_scaled - reconstructed) ** 2))\n",
    "\n",
    "print(f'AE -> MSE={mse_ae:.6f}, Total EVR={evr_total:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mse</th>\n",
       "      <th>total_evr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EFA</td>\n",
       "      <td>0.737914</td>\n",
       "      <td>0.262086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA</td>\n",
       "      <td>0.728905</td>\n",
       "      <td>0.271095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>0.579299</td>\n",
       "      <td>0.420823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model       mse  total_evr\n",
       "0          EFA  0.737914   0.262086\n",
       "1          PCA  0.728905   0.271095\n",
       "2  Autoencoder  0.579299   0.420823"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = pd.DataFrame(\n",
    "    [\n",
    "        {'model': 'EFA', 'mse': mse_efa, 'total_evr': evr_efa},\n",
    "        {'model': 'PCA', 'mse': mse_pca, 'total_evr': evr_pca},\n",
    "        {'model': 'Autoencoder', 'mse': mse_ae, 'total_evr': evr_total},\n",
    "    ]\n",
    ")\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c0442e",
   "metadata": {},
   "source": [
    "Compare validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5573f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reading data dictionary …\n",
      "\n",
      "=== sex ===\n",
      "  reading ph_p_pds.csv ...\n",
      "  -> generated sex in memory  (11868 rows, 2 columns)\n",
      "\n",
      "=== site ===\n",
      "  reading abcd_y_lt.csv ...\n",
      "  -> generated site in memory  (11868 rows, 2 columns)\n",
      "\n",
      "=== age ===\n",
      "  reading abcd_y_lt.csv ...\n",
      "  -> generated age in memory  (11868 rows, 2 columns)\n",
      "(11868, 4) Index(['src_subject_id', 'pubertal_sex_p', 'site_id_l', 'interview_age'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ROOT = Path(r\"G:\\ABCD\\abcd-data-release-5.1\")\n",
    "DICT = Path(r\"G:\\ABCD\\datadict51.xlsx\")\n",
    "\n",
    "validators = {\n",
    "    \"sex\"   : [\"pubertal_sex_p\"],\n",
    "    \"site\" : [\"site_id_l\"],\n",
    "    \"age\"   : [\"interview_age\"],\n",
    "}\n",
    "\n",
    "# ======== 2│运行并输出 ========\n",
    "out_frames, wide = build_validators_baseline(\n",
    "    root=ROOT,\n",
    "    dict_path=DICT,\n",
    "    validators=validators,\n",
    "    eventname=\"baseline_year_1_arm_1\",\n",
    "    out_dir=None,            # 会输出各 tag 的 *_baseline.csv\n",
    "    dict_sheet=None,                      # 若 datadict 只有一个 sheet，可不用填\n",
    "    dict_engine=\"openpyxl\",\n",
    "    verbose=True,\n",
    "    wide_table_name=\"covariates_baseline.csv\"\n",
    ")\n",
    "\n",
    "# wide 就是 validators_baseline.csv 的 DataFrame 对象\n",
    "print(wide.shape, wide.columns[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cc454b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "AE_scores = build_model_scores(qns, latent_factors)\n",
    "# combine wide and AE_scores on src_subject_id\n",
    "validators_df = build_10_items_validators(validators_csv = \"../output/validators/validators_baseline.csv\")\n",
    "\n",
    "nn_result = AE_scores.merge(\n",
    "    validators_df,\n",
    "    on=\"src_subject_id\",\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f53a7b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = qns.iloc[:, 0]\n",
    "efa_scores_df = pd.DataFrame(efa_scores, columns=[f\"efa_{i+1}\" for i in range(efa_scores.shape[1])])\n",
    "efa_scores_df.insert(0, \"src_subject_id\", subject_id)\n",
    "\n",
    "efa_result = efa_scores_df.merge(\n",
    "    validators_df,\n",
    "    on=\"src_subject_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "# efa_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b717cefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = qns.iloc[:, 0]\n",
    "pca_scores_df = pd.DataFrame(pca_scores, columns=[f\"pca_{i+1}\" for i in range(pca_scores.shape[1])])\n",
    "pca_scores_df.insert(0, \"src_subject_id\", subject_id)\n",
    "pca_result = pca_scores_df.merge(\n",
    "    validators_df,\n",
    "    on=\"src_subject_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "# pca_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b27fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validator: dev_delay\n",
      "EFA  - Linear: 0.018, MLP: 0.013\n",
      "AE   - Linear: 0.009, MLP: 0.016\n",
      "PCA  - Linear: 0.023, MLP: 0.022\n",
      "Validator: fes_conflict\n",
      "EFA  - Linear: 0.029, MLP: 0.038\n",
      "AE   - Linear: 0.023, MLP: 0.026\n",
      "PCA  - Linear: 0.030, MLP: 0.026\n",
      "Validator: n_friends\n",
      "EFA  - Linear: 0.011, MLP: 0.012\n",
      "AE   - Linear: 0.006, MLP: 0.003\n",
      "PCA  - Linear: 0.014, MLP: 0.015\n",
      "Validator: school_conn\n",
      "EFA  - Linear: 0.023, MLP: 0.020\n",
      "AE   - Linear: 0.022, MLP: 0.015\n",
      "PCA  - Linear: 0.023, MLP: 0.017\n",
      "Validator: avg_grades\n",
      "EFA  - Linear: 0.143, MLP: 0.155\n",
      "AE   - Linear: 0.101, MLP: 0.115\n",
      "PCA  - Linear: 0.143, MLP: 0.156\n",
      "Validator: fluid_cog\n",
      "EFA  - Linear: 0.049, MLP: 0.058\n",
      "AE   - Linear: 0.031, MLP: 0.038\n",
      "PCA  - Linear: 0.050, MLP: 0.056\n",
      "Validator: cryst_cog\n",
      "EFA  - Linear: 0.050, MLP: 0.057\n",
      "AE   - Linear: 0.027, MLP: 0.044\n",
      "PCA  - Linear: 0.049, MLP: 0.053\n",
      "Validator: mh_service\n",
      "EFA  - Linear: 0.167, MLP: 0.161\n",
      "AE   - Linear: 0.119, MLP: 0.149\n",
      "PCA  - Linear: 0.162, MLP: 0.155\n",
      "Validator: med_history\n",
      "EFA  - Linear: 0.021, MLP: 0.021\n",
      "AE   - Linear: 0.006, MLP: 0.013\n",
      "PCA  - Linear: 0.030, MLP: 0.030\n",
      "Validator: brought_meds\n",
      "EFA  - Linear: 0.025, MLP: 0.024\n",
      "AE   - Linear: 0.011, MLP: 0.009\n",
      "PCA  - Linear: 0.033, MLP: 0.032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def standardize(X):\n",
    "    mean = X.mean(axis=0)\n",
    "    std = X.std(axis=0, ddof=1).replace(0, 1)\n",
    "    return (X - mean) / std\n",
    "\n",
    "for validator_used in [\"dev_delay\", \"fes_conflict\", \"n_friends\", \"school_conn\", \"avg_grades\", \n",
    "                       \"fluid_cog\", \"cryst_cog\", \"mh_service\", \"med_history\", \"brought_meds\"]:\n",
    "\n",
    "    # ===== 1. 取 EFA 因子 =====\n",
    "    tmp = efa_result[[f\"efa_{f}\" for f in range(1, 5)] + [validator_used]].dropna()\n",
    "    X_efa = tmp[[f\"efa_{f}\" for f in range(1, 5)]]\n",
    "    y = tmp[validator_used]\n",
    "\n",
    "    X_efa_scaled = standardize(X_efa)\n",
    "\n",
    "    # ===== 2. 取 AE latent（假设 ae_result 有 ae_1...ae_5）=====\n",
    "    tmp_ae = nn_result[[f\"factor_{i}\" for i in range(1, 5)] + [validator_used]].dropna()\n",
    "    X_ae = tmp_ae[[f\"factor_{i}\" for i in range(1, 5)]]\n",
    "    y_ae = tmp_ae[validator_used]\n",
    "    X_ae_scaled = standardize(X_ae)\n",
    "\n",
    "    tmp_pca = pca_result[[f\"pca_{f}\" for f in range(1, 5)] + [validator_used]].dropna()\n",
    "    X_pca = tmp_pca[[f\"pca_{f}\" for f in range(1, 5)]]\n",
    "    y_pca = tmp_pca[validator_used]\n",
    "\n",
    "    X_pca_scaled = standardize(X_pca)\n",
    "\n",
    "    # 保证 y / y_ae 对齐的话，可以先 merge 再分，但这里先简写思路\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    # 线性模型\n",
    "    lin = LinearRegression()\n",
    "    r2_efa_lin = cross_val_score(lin, X_efa_scaled, y, cv=kf, scoring=\"r2\").mean()\n",
    "    r2_ae_lin  = cross_val_score(lin, X_ae_scaled, y_ae, cv=kf, scoring=\"r2\").mean()\n",
    "    r2_pca_lin = cross_val_score(lin, X_pca_scaled, y_pca, cv=kf, scoring=\"r2\").mean()\n",
    "\n",
    "    # 非线性：MLP\n",
    "    model = MLPRegressor(hidden_layer_sizes=(32, 16),\n",
    "                    activation=\"relu\",\n",
    "                    random_state=seed,\n",
    "                    max_iter=1000)\n",
    "    # model = RandomForestRegressor(n_estimators=100,\n",
    "    #                               max_depth=5)\n",
    "    r2_efa_mlp = cross_val_score(model, X_efa_scaled, y, cv=kf, scoring=\"r2\").mean()\n",
    "    r2_ae_mlp  = cross_val_score(model, X_ae_scaled, y_ae, cv=kf, scoring=\"r2\").mean()\n",
    "    r2_pca_mlp = cross_val_score(model, X_pca_scaled, y_pca, cv=kf, scoring=\"r2\").mean()\n",
    "    \n",
    "    print(f\"Validator: {validator_used}\")\n",
    "    print(f\"EFA  - Linear: {r2_efa_lin:.3f}, MLP: {r2_efa_mlp:.3f}\")\n",
    "    print(f\"AE   - Linear: {r2_ae_lin:.3f}, MLP: {r2_ae_mlp:.3f}\")\n",
    "    print(f\"PCA  - Linear: {r2_pca_lin:.3f}, MLP: {r2_pca_mlp:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
