{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1016af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from models import Autoencoder\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from utils import translate_text\n",
    "from sklearn.model_selection import KFold\n",
    "import shap\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn.functional as F\n",
    "import io\n",
    "from PIL import Image\n",
    "from utils import get_cbcl_details\n",
    "import random\n",
    "import netron\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "from model_code import *\n",
    "import ncv as nested_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7111c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 8  # 你可以设成其他任何整数\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # 多卡也能同步\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fa1012",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06064f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dir = Path(os.getcwd())\n",
    "data_path = code_dir.parent / \"data\"\n",
    "assert os.path.exists(\n",
    "    data_path\n",
    "), \"Data directory not found. Make sure you're running this code from the root directory of the project.\"\n",
    "\n",
    "with open(data_path / \"cbcl_data_remove_unrelated.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    qns = pd.read_csv(f)\n",
    "\n",
    "X = qns.iloc[:, 1:].values\n",
    "\n",
    "# Standardize the data\n",
    "# scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train_raw, X_temp = train_test_split(X, test_size=0.2)\n",
    "X_val_raw, X_test_raw = train_test_split(X_temp, test_size=0.5)\n",
    "\n",
    "\n",
    "X_train = scaler.fit_transform(X_train_raw)\n",
    "X_val = scaler.transform(X_val_raw)\n",
    "X_test = scaler.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c9f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_cbcl_details\n",
    "items = [get_cbcl_details(col) for col in qns.iloc[:, 1:].columns]\n",
    "items = np.array(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703854b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import find_column_in_csvs\n",
    "\n",
    "find_column_in_csvs(\n",
    "    root_folder=r'G:\\ABCD\\abcd-data-release-5.1',\n",
    "    target_column='kbi_p_conflict_causes___10'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1fdd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d74151",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef4e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === AE ===\n",
    "ae_scores, ae_best = nested_cv.OptimizeAE(X_train)\n",
    "print(\"==== AE Result ====\")\n",
    "print(\"AE outer test MSEs:\", ae_scores)\n",
    "print(\"AE best hyperparameters:\", ae_best)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cebdeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SparseAE ===\n",
    "sparse_scores, sparse_best = nested_cv.OptimizeSparseAE(X_train)\n",
    "print(\"==== SparseAE Result ====\")\n",
    "print(\"SparseAE outer test MSEs:\", sparse_scores)\n",
    "print(\"SparseAE best hyperparameters:\", sparse_best)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba7cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VAE ===\n",
    "vae_scores, vae_best = nested_cv.OptimizeVAE(X_train)\n",
    "print(\"==== VAE Result ====\")\n",
    "print(\"VAE outer test MSEs:\", vae_scores)\n",
    "print(\"VAE best hyperparameters:\", vae_best)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d6ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === BetaVAE ===\n",
    "beta_scores, beta_best = nested_cv.OptimizeBetaVAE(X_train)\n",
    "print(\"==== BetaVAE Result ====\")\n",
    "print(\"BetaVAE outer test MSEs:\", beta_scores)\n",
    "print(\"BetaVAE best hyperparameters:\", beta_best)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d640b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==== BetaVAE Result ====\")\n",
    "print(\"BetaVAE outer test MSEs:\", beta_scores)\n",
    "print(\"BetaVAE best hyperparameters:\", beta_best)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f76559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import model_code\n",
    "importlib.reload(model_code)\n",
    "from model_code import *   # 再次显式导入其中的类/函数\n",
    "import ncv\n",
    "importlib.reload(ncv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ecf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === COAE ===\n",
    "coae_scores, coae_best = nested_cv.OptimizeCOAE(X_train)\n",
    "print(\"==== COAE Result ====\")\n",
    "print(\"COAE outer test MSEs:\", coae_scores)\n",
    "print(\"COAE best hyperparameters:\", coae_best)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155a1287",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==== COAE Result ====\")\n",
    "print(\"COAE outer test MSEs:\", coae_scores)\n",
    "print(\"COAE best hyperparameters:\", coae_best)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6fc5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FactorVAE ===\n",
    "fv_scores, fv_best = nested_cv.OptimizeFactorVAE(X_train)\n",
    "print(\"==== FactorVAE Result ====\")\n",
    "print(\"FactorVAE outer test MSEs:\", fv_scores)\n",
    "print(\"FactorVAE best hyperparameters:\", fv_best)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ea3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==== FactorVAE Result ====\")\n",
    "print(\"FactorVAE outer test MSEs:\", fv_scores)\n",
    "print(\"FactorVAE best hyperparameters:\", fv_best)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161f3486",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd71827",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(\n",
    "    X_train, X_val,\n",
    "    encoding_dim=5,\n",
    "    layer1_neurons=128,\n",
    "    layer2_neurons=64,\n",
    "    layer3_neurons=32,         \n",
    ")\n",
    "autoencoder.train(show_plot=True)\n",
    "\n",
    "latent_factors, rec_errors, explained_variance_ratios, explained_variance_ratio_total, reconstructed = autoencoder.evaluate_on_data(X_train)\n",
    "explained_variance_ratio_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b2769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例参数\n",
    "encoding_dim = 5\n",
    "layer1_neurons = 127\n",
    "layer2_neurons = 117\n",
    "layer3_neurons = 106\n",
    "# layer1_neurons = 128\n",
    "# layer2_neurons = 64\n",
    "# layer3_neurons = 32\n",
    "# layer4_neurons = 90\n",
    "# n_clusters = 4  # 可根据需要调整聚类数\n",
    "\n",
    "# 初始化 COAETrainer（推荐使用该封装）\n",
    "autoencoder = SparseAutoencoder(\n",
    "    X_train=X_train,\n",
    "    X_val=X_val,\n",
    "    encoding_dim=encoding_dim,\n",
    "    layer1_neurons=layer1_neurons,\n",
    "    layer2_neurons=layer2_neurons,\n",
    "    layer3_neurons=layer3_neurons,\n",
    "    # layer4_neurons=layer4_neurons,\n",
    "    # n_clusters=n_clusters\n",
    ")\n",
    "\n",
    "# 开始训练\n",
    "autoencoder.train(show_plot=True)\n",
    "# autoencoder.export_to_onnx(X_train, onnx_path = \"../output/sparse_autoencoder.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd908373",
   "metadata": {},
   "source": [
    "## sparse AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f3b231",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparseAE = SparseAutoencoder(\n",
    "    X_train=X_train,\n",
    "    X_val=X_val,\n",
    "    encoding_dim=5,             # 必须提供，潜在维度\n",
    "    layer1_neurons=128,\n",
    "    layer2_neurons=64,\n",
    "    layer3_neurons=32,\n",
    "    sparsity_target=0.05,\n",
    "    beta=1.0,\n",
    ")\n",
    "\n",
    "sparseAE.train(show_plot=True)\n",
    "\n",
    "# 评估\n",
    "mu_z, rec_errs, evr_each, evr_total, X_recon = sparseAE.evaluate_on_data(X_test)\n",
    "print(\"Explained Variance Ratio (total):\", evr_total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614184f3",
   "metadata": {},
   "source": [
    "## COAutoencoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51dd8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "coae = COAETrainer(X_train, X_val, \n",
    "    latent_dim=5, \n",
    "    layer1=128, \n",
    "    layer2=64, \n",
    "    layer3=32, \n",
    "    n_clusters=5)\n",
    "coae.train(show_plot=True)\n",
    "\n",
    "z, rec_errs, evr_each, evr_total, X_recon = coae.evaluate_on_data(X_train)\n",
    "\n",
    "print(\"Total Explained Variance Ratio (COAE):\", evr_total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d3da9d",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VariationalAutoencoder(\n",
    "    X_train, X_val,\n",
    "    encoding_dim=5,\n",
    "    layer1_neurons=128,\n",
    "    layer2_neurons=64,\n",
    "    layer3_neurons=32,\n",
    "    beta_kl=0.1          # β-VAE 可自由调节\n",
    ")\n",
    "vae.train(show_plot=True)\n",
    "\n",
    "mu_z, rec_errs, evr_each, evr_total, X_recon = vae.evaluate_on_data(X_test)\n",
    "evr_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2316910",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_z, rec_errs, evr_each, evr_total, X_recon = vae.evaluate_on_data(X_train)\n",
    "evr_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549c121e",
   "metadata": {},
   "source": [
    "## Beta VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f349cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bvae = BetaVAE(\n",
    "    X_train, X_val,\n",
    "    encoding_dim=5,\n",
    "    layer1_neurons=128,\n",
    "    layer2_neurons=64,\n",
    "    layer3_neurons=32,         # β-VAE 可自由调节\n",
    ")\n",
    "bvae.train(show_plot=True)\n",
    "\n",
    "latent_factors, rec_errors, explained_variance_ratios, explained_variance_ratio_total, reconstructed = bvae.evaluate_on_data(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f87af72",
   "metadata": {},
   "source": [
    "## FactorVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b75460",
   "metadata": {},
   "source": [
    "## NMF-AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cf3738",
   "metadata": {},
   "source": [
    "## NMF-Factor-AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3739c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent, errs, ratios, total_ratio, recon = trainer.evaluate_on_data(X_train_np)\n",
    "print(f\"FactorVAE+NMF 总体方差解释率: {total_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a91b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent, errs, ratios, total_ratio, recon = trainer.evaluate_on_data(X_test)\n",
    "print(f\"FactorVAE+NMF 总体方差解释率: {total_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5234fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ve_per_feature = 1 - np.var(X_train - reconstructed.cpu().numpy(), axis=0) / np.var(X_train, axis=0)\n",
    "print(\"每道题的解释方差率:\", ve_per_feature)\n",
    "# 输出小于 0.1 的题目\n",
    "low_variance_items = np.where(ve_per_feature < 0.1)[0]\n",
    "\n",
    "print(\"解释方差率小于 0.1 的题目索引:\", low_variance_items)\n",
    "\n",
    "print(\"解释方差率小于 0.1 的题目:\", items[low_variance_items])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a181f12",
   "metadata": {},
   "source": [
    "# Interpretability for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b955cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_factors = (\n",
    "    latent_factors.values\n",
    "    if isinstance(latent_factors, pd.DataFrame)\n",
    "    else latent_factors\n",
    ")\n",
    "# original_features = X if isinstance(X, np.ndarray) else X.values\n",
    "original_features = (\n",
    "    X_train if isinstance(X_train, np.ndarray) else X_train.values\n",
    ")\n",
    "\n",
    "# 存储每个原始特征的回归系数\n",
    "n_original_features = original_features.shape[1]\n",
    "n_latent_factors = latent_factors.shape[1]\n",
    "scaler = StandardScaler()\n",
    "latent_factors_scaled = scaler.fit_transform(latent_factors)\n",
    "loadings = []\n",
    "\n",
    "# 对每个原始特征进行回归，使用 latent_factors 作为输入特征\n",
    "for i in range(n_original_features):\n",
    "    y = original_features[:, i]  # 当前原始特征\n",
    "    reg = LinearRegression().fit(latent_factors, y)\n",
    "    loadings.append(reg.coef_)\n",
    "\n",
    "# 将结果转换为 DataFrame，便于查看\n",
    "loadings_df = pd.DataFrame(\n",
    "    loadings, columns=[f\"Latent_{j+1}\" for j in range(n_latent_factors)]\n",
    ")\n",
    "# loadings_df.index = [f\"Feature_{i+1}\" for i in range(n_original_features)]\n",
    "loadings_df.index = items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375f7a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings_df = loadings_df.reindex(\n",
    "    loadings_df['Latent_1'].abs().sort_values(ascending=False).index\n",
    ")\n",
    "loadings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a45e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def average_absolute_correlation(matrix):\n",
    "    \"\"\"\n",
    "    计算输入矩阵各列之间的平均绝对相关系数。\n",
    "    \n",
    "    参数:\n",
    "        matrix: shape (N, d)，这里假定每行是一个样本，每列是一个factor/loading\n",
    "    \n",
    "    返回:\n",
    "        avg_abs_corr: 所有列两两相关系数取绝对值后的平均值\n",
    "    \"\"\"\n",
    "    # 1) 计算 d x d 的相关系数矩阵 (列 vs 列)\n",
    "    corr_matrix = np.corrcoef(matrix, rowvar=False)  # rowvar=False表示按列计算相关\n",
    "    \n",
    "    # 2) 取上三角（不含对角线）的索引\n",
    "    d = corr_matrix.shape[0]\n",
    "    upper_tri_indices = np.triu_indices(d, k=1)  # (行索引数组, 列索引数组)\n",
    "    \n",
    "    # 3) 取出相关系数，并计算其绝对值\n",
    "    off_diag_corr_values = corr_matrix[upper_tri_indices]  # 非对角线元素\n",
    "    abs_off_diag = np.abs(off_diag_corr_values)\n",
    "    \n",
    "    # 4) 求平均\n",
    "    avg_abs_corr = np.mean(abs_off_diag)\n",
    "    \n",
    "    return avg_abs_corr\n",
    "\n",
    "\n",
    "# ==== 示例用法 ====\n",
    "if __name__ == \"__main__\":\n",
    "    # 模拟一个 latent factor 矩阵, shape = (N, d)\n",
    "    # 比如 N=1000, d=5    \n",
    "    # 计算 latent factors 的平均绝对相关\n",
    "    avg_corr_latent = average_absolute_correlation(latent_factors)\n",
    "    print(\"Average absolute correlation of latent factors:\", avg_corr_latent)\n",
    "    \n",
    "    # 如果有 loading_factors 矩阵，同理：\n",
    "    # loading_factors = ...\n",
    "    # avg_corr_loading = average_absolute_correlation(loading_factors)\n",
    "    # print(\"Average absolute correlation of loading factors:\", avg_corr_loading)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eaea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 设置风格\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# 遍历每一列（latent）\n",
    "for col in loadings_df.columns:\n",
    "    # 获取当前列绝对值最大的前5个特征（CBCL item）\n",
    "    top5 = loadings_df[col].abs().sort_values(ascending=False).head(8).index\n",
    "    top5_data = loadings_df.loc[top5, [col]]\n",
    "\n",
    "    # 绘图\n",
    "    plt.figure(figsize=(6, 3))  # 每张图小一些方便展示\n",
    "    sns.heatmap(top5_data, annot=True, cmap='coolwarm', center=0, cbar=True)\n",
    "    plt.title(f\"Top 5 CBCL Loadings for {col}\")\n",
    "    plt.xlabel(\"Latent Dimension\")\n",
    "    plt.ylabel(\"CBCL Item\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61d7e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(20, 80))\n",
    "sns.heatmap(loadings_df, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title(\"CBCL Loadings Heatmap\")\n",
    "plt.xlabel(\"Latent Dimensions\")\n",
    "plt.ylabel(\"CBCL Items\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5c008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# model = autoencoder.get_model().encoder\n",
    "# model =model.Encoder()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "background = X_train[np.random.choice(X_train.shape[0], 100, replace=False)]\n",
    "\n",
    "explainer = shap.DeepExplainer(model, torch.tensor(background, dtype=torch.float32).to(device), )\n",
    "\n",
    "# 计算 SHAP 值\n",
    "shap_values = explainer.shap_values(torch.tensor(X_test[:20], dtype=torch.float32).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e7d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "# We'll store each SHAP summary_plot as an in-memory PNG, then display them\n",
    "images = []\n",
    "\n",
    "for i in range(5):\n",
    "    # 1) Create the SHAP summary plot on a brand-new figure\n",
    "    shap.summary_plot(shap_values[:,:,i], X_test[:20], feature_names=items, show=False)\n",
    "    plt.xlim(shap_values.min(), shap_values.max())\n",
    "    \n",
    "    # 2) Grab that just-created figure object\n",
    "    tmp_fig = plt.gcf()\n",
    "    \n",
    "    # 3) Save it to a buffer in PNG format\n",
    "    buf = io.BytesIO()\n",
    "    tmp_fig.savefig(buf, format='png', bbox_inches='tight', dpi=300)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # 4) Convert buffer -> PIL image and store\n",
    "    images.append(Image.open(buf))\n",
    "    \n",
    "    # 5) Close that figure to avoid overlapping the next iteration\n",
    "    plt.close(tmp_fig)\n",
    "\n",
    "# Now create a single \"master\" figure of 1 row × 4 columns\n",
    "fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(20,5), dpi=1000)\n",
    "\n",
    "for idx, ax in enumerate(axes):\n",
    "    # 6) Display each PIL image in its own subplot\n",
    "    ax.imshow(images[idx])\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(f\"Factor {idx}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
